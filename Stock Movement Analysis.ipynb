{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a136912e",
   "metadata": {},
   "source": [
    "# Stock Movement Analysis Based on Social Media Sentiment\n",
    "This notebook demonstrates scraping data from **Reddit**, preprocessing it for sentiment analysis, and performing basic feature engineering. We will conclude by preparing the data for a simple stock movement prediction model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b51ca12-3f84-4f8b-8e09-eeacd4711057",
   "metadata": {},
   "source": [
    "## Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75080b0b-81f8-4757-b7b8-b02ccc4fa12a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries are installed and imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from textblob import TextBlob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import yfinance as yf\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "print(\"All libraries are installed and imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c10dcf2-8233-4a01-9f3c-5f4f072f39f3",
   "metadata": {},
   "source": [
    "## Set Up Reddit API Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85a01d1f-4987-4f1a-931e-eeb79c27389d",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "client_id = os.getenv('REDDIT_CLIENT_ID')\n",
    "client_secret = os.getenv('REDDIT_CLIENT_SECRET')\n",
    "user_agent = os.getenv('REDDIT_USER_AGENT')\n",
    "\n",
    "reddit = praw.Reddit(\n",
    "    client_id=client_id,         \n",
    "    client_secret=client_secret, \n",
    "    user_agent=user_agent       \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2533de",
   "metadata": {},
   "source": [
    "## Reddit Data Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82a3965f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               title   timestamp\n",
      "0  r/Stocks Daily Discussion & Fundamentals Frida...  2024-11-15\n",
      "1  /r/Stocks Weekend Discussion Saturday - Nov 23...  2024-11-23\n",
      "2  Glancy Prongay & Murray LLP, a Leading Securit...  2024-11-24\n",
      "3          Evaluation of Companies with Down Revenue  2024-11-23\n",
      "4  Thoughts on ESTC (Elastic) as the next hot AI ...  2024-11-23\n"
     ]
    }
   ],
   "source": [
    "def fetch_reddit_posts(subreddit_name, limit=100):\n",
    "    subreddit = reddit.subreddit(subreddit_name)\n",
    "    posts = []\n",
    "    for post in subreddit.hot(limit=limit):\n",
    "        posts.append({\n",
    "            'title': post.title,\n",
    "            'timestamp': pd.to_datetime(post.created_utc, unit='s').date()  # Convert to datetime.date\n",
    "        })\n",
    "    return pd.DataFrame(posts)\n",
    "\n",
    "reddit_data = fetch_reddit_posts(subreddit_name='stocks', limit=100)\n",
    "print(reddit_data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435a245a",
   "metadata": {},
   "source": [
    "Preprocessing and Sentiment Analysis\n",
    "We'll preprocess the scraped text data and perform sentiment analysis using TextBlob."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26561ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               title  timestamp  sentiment\n",
      "0  r/Stocks Daily Discussion & Fundamentals Frida... 2024-11-15   0.000000\n",
      "1  /r/Stocks Weekend Discussion Saturday - Nov 23... 2024-11-23   0.000000\n",
      "2  Glancy Prongay & Murray LLP, a Leading Securit... 2024-11-24  -0.200000\n",
      "3          Evaluation of Companies with Down Revenue 2024-11-23  -0.155556\n",
      "4  Thoughts on ESTC (Elastic) as the next hot AI ... 2024-11-23   0.125000\n"
     ]
    }
   ],
   "source": [
    "def preprocess_and_analyze(data, text_column):\n",
    "    def clean_text(text):\n",
    "        return ' '.join(word for word in text.split() if not word.startswith(('http', '@', '#')))\n",
    "\n",
    "    def get_sentiment(text):\n",
    "        return TextBlob(text).sentiment.polarity\n",
    "\n",
    "    data['cleaned_text'] = data[text_column].apply(clean_text)\n",
    "    # Analyze sentiment\n",
    "    data['sentiment'] = data['cleaned_text'].apply(get_sentiment)\n",
    "    return data\n",
    "\n",
    "reddit_data = preprocess_and_analyze(reddit_data, text_column='title')\n",
    "\n",
    "reddit_data['timestamp'] = pd.to_datetime(reddit_data['timestamp'])  # Make sure it's a datetime object\n",
    "\n",
    "print(reddit_data[['title', 'timestamp', 'sentiment']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc65cb7",
   "metadata": {},
   "source": [
    "## Fetch Historical Stock Data (SPY or QQQ) Using yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "662208b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Data with Returns and Movement:\n",
      "             Adj Close   returns stock_movement\n",
      "Date                                           \n",
      "2023-01-04  374.483368  0.007720             Up\n",
      "2023-01-05  370.209229 -0.011413           Down\n",
      "2023-01-06  378.698914  0.022932             Up\n",
      "2023-01-09  378.484222 -0.000567           Down\n",
      "2023-01-10  381.138458  0.007013             Up\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Fetch Historical Stock Data (SPY or QQQ) Using yfinance\n",
    "def fetch_stock_data(ticker, start_date, end_date):\n",
    "    stock_data = yf.download(ticker, start=start_date, end=end_date)\n",
    "    return stock_data[['Adj Close']].copy()  # Ensure it's a copy\n",
    "\n",
    "# Fetch SPY (S&P 500 ETF) data from yfinance\n",
    "stock_data = fetch_stock_data('SPY', start_date='2023-01-01', end_date='2024-11-30')\n",
    "\n",
    "stock_data['returns'] = stock_data['Adj Close'].pct_change()\n",
    "\n",
    "stock_data['stock_movement'] = np.where(stock_data['returns'] > 0, 'Up', 'Down')\n",
    "\n",
    "stock_data.dropna(inplace=True)\n",
    "\n",
    "print(\"Stock Data with Returns and Movement:\")\n",
    "print(stock_data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ca74ce",
   "metadata": {},
   "source": [
    "## Combine Reddit Sentiment Data with Stock Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e77a9612",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Adj Close   returns stock_movement  timestamp  sentiment\n",
      "0  585.750000 -0.012809           Down 2024-11-15        0.0\n",
      "1  588.150024  0.004097             Up 2024-11-18        0.2\n",
      "2  588.150024  0.004097             Up 2024-11-18        0.0\n",
      "3  588.150024  0.004097             Up 2024-11-18        0.0\n",
      "4  588.150024  0.004097             Up 2024-11-18        0.0\n"
     ]
    }
   ],
   "source": [
    "reddit_data['timestamp'] = pd.to_datetime(reddit_data['timestamp'])\n",
    "\n",
    "stock_data['timestamp'] = pd.to_datetime(stock_data.index)\n",
    "\n",
    "combined_data = pd.merge(stock_data, reddit_data[['timestamp', 'sentiment']], on='timestamp', how='inner')\n",
    "\n",
    "print(combined_data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c47b514-0691-4db0-8b5a-1703f317443e",
   "metadata": {},
   "source": [
    "## Training and predicting Stock Movements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe2e9736-449a-41e0-92b1-1f726f5a00f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9375\n",
      "\n",
      "Model Prediction Accuracy: 93.75%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.00      0.00      0.00         1\n",
      "          Up       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.94        16\n",
      "   macro avg       0.47      0.50      0.48        16\n",
      "weighted avg       0.88      0.94      0.91        16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = combined_data[['sentiment']]  # Feature: Sentiment\n",
    "y = combined_data['stock_movement']  # Target: Stock Movement\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"\\nModel Prediction Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a70ad94-224d-4088-ba17-2bd2aa56d96a",
   "metadata": {},
   "source": [
    "## Improvements that an be done:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f7a251-1e34-43ff-9090-9d615338eea6",
   "metadata": {},
   "source": [
    "- **Data Preprocessing**: Improve text cleaning, handle missing data.\n",
    "- **Feature Engineering**: Add more features like moving averages, technical indicators.\n",
    "- **Modeling**: Tune hyperparameters, try other models like XGBoost or LSTM.\n",
    "- **Sentiment Analysis**: Use advanced models like VADER or BERT.\n",
    "- **Evaluation**: Address class imbalance, use more evaluation metrics.\n",
    "- **Time Series**: Try LSTM for better temporal analysis.\n",
    "- **Visualization**: Visualize sentiment trends with stock prices.\n",
    "- **Real-Time**: Build a real-time prediction system.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
